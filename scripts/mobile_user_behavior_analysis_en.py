# -*- coding: utf-8 -*-
"""mobile_user_behavior_analysis_en.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ANNtyAkNsWR999OASPQQcE7VmGiMB73Z

## üì± Analysis of Mobile Device User Behavior
This project uses a dataset containing mobile device usage patterns to classify user behavior into **five categories**.

### üîã Key Features:
- **Daily app usage time**, screen-on time, and battery consumption.
- **Data usage** and number of installed apps.
- **User demographics**: Age, Gender, Device Model, and Operating System.

### üóÇÔ∏è Applications:
- **Predicting the behavior** of mobile device users.
- Identifying **trends in battery and data consumption**.
- Supporting the **development and optimization of applications**.


---
"""

import numpy as np
import pandas as pd
import seaborn as sb
import matplotlib.pyplot as plt
import sklearn as skl
import scipy as sp
from sklearn.decomposition import PCA
from sklearn.metrics import adjusted_rand_score, silhouette_score
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder, StandardScaler
import kagglehub

file_path = "/content/user_behavior_dataset.csv"
df = pd.read_csv(file_path)

df.head()

df.tail()

"""### üïπÔ∏è Explanation of the User Behavior Class Column
The dataset classifies users into **five categories** based on their mobile usage patterns:

1. **Minimal User**: Rare device usage; low app usage time and data consumption.
2. **Light User**: Occasional usage for basic tasks; moderate screen time.
3. **Average User**: Balanced usage for work, social media, and entertainment.
4. **Intense User**: Heavy usage for gaming, streaming, or multitasking.
5. **Extreme User**: Intense usage, often for professional purposes or gaming.

This classification **is essential** for identifying and analyzing different types of mobile users, making the dataset valuable for clustering and behavioral analysis.


---
### üïπÔ∏èExplica√ß√£o da Coluna User Behavior Class (Comportamento de Usu√°rio)
O conjunto de dados classifica os usu√°rios em **cinco categorias** com base em seus padr√µes de uso m√≥vel:

1. **Usu√°rio M√≠nimo**: Uso raro do dispositivo; baixo tempo de uso de aplicativos e consumo de dados.
2. **Usu√°rio Leve**: Uso ocasional para tarefas b√°sicas; tempo de tela moderado.
3. **Usu√°rio M√©dio**: Uso equilibrado para trabalho, redes sociais e entretenimento.
4. **Usu√°rio Intenso**: Alto uso para jogos, streaming ou multitarefa.
5. **Usu√°rio Extremo**: Uso intenso, geralmente para fins profissionais ou jogos.

Essa classifica√ß√£o **√© essencial** para identificar e analisar diferentes tipos de usu√°rios m√≥veis, tornando o conjunto de dados valioso para agrupamento e an√°lise de comportamento.

---

## üåü Analysis Question:

**How can mobile usage patterns be grouped to identify different types of users?**  
   - Cluster analysis to explore and validate existing behavioral segmentation.
"""

df.info()

"""### üîç Summary of `info()`

- **Entries and Columns:**
  - The dataset contains **700 rows** and **11 columns**.

- **Data Types:**
  - **Numerical:** `App Usage Time`, `Screen On Time`, `Battery Drain`, `Number of Apps Installed`, `Data Usage`, `Age`.
  - **Categorical:** `Device Model`, `Operating System`, `Gender`, `User Behavior Class`.

- **Missing Values:**
  - **No missing values.** All columns have 700 valid entries.

- **Memory Size:**
  - The dataset occupies **60.3 KB** of memory, making it lightweight and easy to process.

---

### üí° Implications
1. **Numerical Columns:**
   - Can be used directly in statistical analyses or to identify correlations.

2. **Categorical Columns:**
   - Need to be encoded for advanced analyses or use in machine learning models.

3. **Complete Dataset:**
   - No missing values, reducing the need for preprocessing.

4. **Efficiency:**
   - The small dataset size allows for quick analyses even on devices with lower computational power.

---

"""

df.describe().transpose()

"""# üìä Statistical Summary of Variables

The descriptive analysis of the dataset's variables provides important insights into mobile usage patterns. The dataset contains **700 samples** in total. Below are the key statistics for each column:

| **Variable**                    | **Mean**  | **Standard Deviation** | **Minimum** | **25%**   | **50% (Median)** | **75%**   | **Maximum** |
|---------------------------------|-----------|-------------------------|-------------|-----------|-------------------|-----------|-------------|
| **App Usage Time (min/day)**    | 271.13    | 177.20                  | 30.0        | 113.25    | 227.5             | 434.25    | 598.0       |
| **Screen On Time (hours/day)**  | 5.27      | 3.07                    | 1.0         | 2.50      | 4.9               | 7.40      | 12.0        |
| **Battery Drain (mAh/day)**     | 1525.16   | 819.14                  | 302.0       | 722.25    | 1502.5            | 2229.50   | 2993.0      |
| **Number of Apps Installed**    | 50.68     | 26.94                   | 10.0        | 26.00     | 49.0              | 74.00     | 99.0        |
| **Data Usage (MB/day)**         | 929.74    | 640.45                  | 102.0       | 373.00    | 823.5             | 1341.00   | 2497.0      |
| **Age**                         | 38.48     | 12.01                   | 18.0        | 28.00     | 38.0              | 49.00     | 59.0        |
| **User Behavior Class**         | 2.99      | 1.40                    | 1.0         | 2.00      | 3.0               | 4.00      | 5.0         |

---

### üîç Conclusions

1. **App Usage Time and Screen On Time**:
   - The average daily app usage time is **271 minutes** (4 hours and 31 minutes), while the average screen-on time is **5.27 hours**.
   - The high variation in app usage (standard deviation of 177.2) indicates highly distinct user profiles.

2. **Battery Consumption and Number of Installed Apps**:
   - The average battery consumption is **1525 mAh per day**, with heavy users reaching nearly **3000 mAh**.
   - The average number of installed apps is **50.68**, ranging from 10 to 99.

3. **Data Usage**:
   - The average daily data usage is **929.74 MB**, with extreme users consuming up to **2.5 GB per day**.

4. **User Age**:
   - The average user age is **38.48 years**, with most users falling in the range of **28 to 49 years**.

5. **Behavior Class**:
   - The behavior classes have a balanced distribution, with a median of **3**, representing an average user.

---

### üí° Implications

- **Pattern Identification**:
   - The large variations in battery and data consumption suggest the existence of distinct user profiles, which will be explored in the clustering analysis.

- **Resource Usage**:
   - High battery and data consumption among heavy users highlights the need for optimization in mobile devices and apps to improve efficiency.

- **Demographic Segmentation**:
   - The predominant age range can guide app design and marketing strategies.

---

## üîß Removal of the `User ID` Column

The `User ID` column was removed as it is irrelevant to the clustering process. Since it has no direct relationship with user behavior or characteristics, its presence could only add noise to the model, reducing the quality of the clusters.
"""

# Remove irrelevant columns
df = df.drop(columns=['User ID'])

"""---

## üñ≤Ô∏è Outlier Detection

We performed an interquartile range (IQR) analysis to check for the presence of outliers in the data. Outlier analysis is essential to ensure that extreme values do not compromise the quality of the model.

### Method Used:
The IQR was calculated for each numerical column, and outliers were identified as values falling outside the range:

"""

numerical_columns = ['App Usage Time (min/day)', 'Screen On Time (hours/day)',
                     'Battery Drain (mAh/day)', 'Number of Apps Installed',
                     'Data Usage (MB/day)', 'Age']

for col in numerical_columns:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f"Coluna {col}: {len(outliers)} outliers")

bins = [18, 25, 35, 45, 60]
labels = ['18-25', '26-35', '36-45', '46-60']
df['Age Group'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)
print(df['Age Group'].unique())  # Check the groups

"""---

## ‚öôÔ∏è Data Normalization

To ensure that all numerical variables are on the same scale and are adequately considered in the model's calculations, we performed data normalization using **StandardScaler**.

### Why Normalize?
- Variables with different scales can influence algorithms like clustering.
- Normalization standardizes the data to have a mean of 0 and a standard deviation of 1.

### Method Used:
We used the `StandardScaler` library from scikit-learn to transform the numerical columns. Each value was adjusted using the formula:

"""

scaler = StandardScaler()
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

"""---

## üîÑ Categorical Data Encoding

To enable machine learning algorithms to interpret categorical variables, we encoded these columns into numerical values using **LabelEncoder**.

### üßë‚Äçüíª Why Encode?
- Algorithms like k-means cannot directly operate on categorical data.
- Transforming these variables into numerical values allows them to be used in calculations and analyses.

### üîå Encoded Columns:
- **Gender**
- **Operating System**
- **Device Model**

### Code Used:
We transformed the columns using the following snippet:

"""

df['Gender'] = LabelEncoder().fit_transform(df['Gender'])
df['Operating System'] = LabelEncoder().fit_transform(df['Operating System'])
df['Device Model'] = LabelEncoder().fit_transform(df['Device Model'])

print(df.dtypes) # Checking if it was converted correctly

"""---

## üè∑Ô∏è Analysis of Existing Classes

Before applying clustering, we explored the predefined classes in the dataset to understand the distribution of entries.

### Code:

"""

classes = df['User Behavior Class'].unique()

# Subsets by class
subsets = {cls: df[df['User Behavior Class'] == cls] for cls in classes}

# Visualize the size of each subset
for cls, subset in subsets.items():
    print(f"Class {cls}: {len(subset)} entries")

"""---
## üéØ **What are the different types of mobile users based on their behavioral patterns?**

### üóÉÔ∏è **Suggested Model: Clustering (unsupervised)**

To identify behavioral patterns among users, I used the **K-Means Clustering** algorithm, grouping users based on the following behavioral variables:

- **App Usage Time (min/day)**  
- **Screen On Time (hours/day)**  
- **Data Usage (MB/day)**  
- **Battery Drain (mAh/day)**  
- **Number of Apps Installed**  

### üîç **Analysis Steps:**
1. **Data Normalization**:  
   All numerical variables were scaled to ensure they have the same influence on the clustering.

2. **Defining the Number of Clusters**:  
   I chose **5 clusters**, aligning them with the predefined behavioral classes for comparison.

3. **Cluster Visualization**:  
   I performed dimensionality reduction using PCA (Principal Component Analysis) to project the clusters into two dimensions, making interpretation easier.

4. **Model Evaluation**:  
   The clustering performance was evaluated using the **Silhouette Score**, which measured the quality of the separation between clusters.

"""

# Select relevant numerical columns for clustering
X = df[['App Usage Time (min/day)', 'Screen On Time (hours/day)',
        'Battery Drain (mAh/day)', 'Number of Apps Installed', 'Data Usage (MB/day)']]

# Define the number of clusters (5, based on the behavioral classes)
kmeans = KMeans(n_clusters=5, random_state=42)
kmeans.fit(X)

# Add the labels to the dataset
df['Cluster'] = kmeans.labels_

# Visualize the count per cluster
print(df['Cluster'].value_counts())

"""---
# üíª Comparison Between Classes and Clusters
"""

# Comparison between original classes and generated clusters
comparison = pd.crosstab(df['User Behavior Class'], df['Cluster'])
print(comparison)

"""### üßÆ Comparison Between Classes and Clusters

When comparing the original user behavior classes with the clusters generated by the clustering model, we observe an **almost perfect match**. This means that the clustering model, based on the provided variables, effectively replicated the existing classes.

---

#### üîç Comparison Details:

**Original Classes:**
- Class 1: 136 entries  
- Class 2: 146 entries  
- Class 3: 143 entries  
- Class 4: 139 entries  
- Class 5: 136 entries  

**Generated Clusters:**
- Cluster 0: 136 entries  
- Cluster 1: 146 entries  
- Cluster 2: 143 entries  
- Cluster 3: 136 entries  
- Cluster 4: 139 entries  

---

#### üìä Contingency Table:
The contingency table below confirms that each cluster corresponds directly to an original class:

| Cluster | Class 1 | Class 2 | Class 3 | Class 4 | Class 5 |
|---------|---------|---------|---------|---------|---------|
| 0       | 0       | 0       | 0       | 0       | 136     |
| 1       | 0       | 146     | 0       | 0       | 0       |
| 2       | 0       | 0       | 143     | 0       | 0       |
| 3       | 136     | 0       | 0       | 0       | 0       |
| 4       | 0       | 0       | 0       | 139     | 0       |

---

#### üìà Conclusion:
The clustering model **perfectly replicated** the original classes. This suggests that:
1. The chosen variables faithfully represent user behavior.
2. The application of clustering in this case simply confirms the existing separation in the original classes.

---
# ü§ñ Cluster Quality Evaluation: Silhouette Score
"""

score = silhouette_score(X, kmeans.labels_)
print(f"Silhouette Score: {score:.2f}")

"""### üßÆ Clustering Evaluation with Silhouette Score

The **Silhouette Score** is a widely used metric to evaluate the quality of clusters generated by clustering algorithms. It measures the separation between clusters and the cohesion within them, with values ranging from -1 to 1. The closer the value is to 1, the better the separation and definition of the clusters.

In our case, the **Silhouette Score was 0.60**. This value indicates that the clusters generated by the model have moderate quality:

- **Cohesion:** Points are reasonably close to the center of their own clusters.
- **Separation:** Clusters show visible separation, but there is some overlap between them.

---

### üîç Interpretation

Although the **Silhouette Score** of 0.60 indicates that the model captured a clustering structure in the data, it does not reflect a perfectly clear separation between clusters. This may be due to:
1. **Data Characteristics:** Some variables may not significantly contribute to group separation.
2. **Cluster Geometry:** Clusters may not be perfectly spherical, which can lower the Silhouette Score.
3. **Alignment with Original Classes:** The model replicated the original classes well, but the Silhouette Score does not directly measure this alignment.

---

### ‚ö†Ô∏è Limitation of the Silhouette Score

The **Silhouette Score** only evaluates geometric separation and does not consider alignment with the original classes. Therefore, even with a perfect match between clusters and classes, the score may be moderate, as in this case.

---

### üìå Conclusion

While the **Silhouette Score** is useful, it should be complemented with other metrics, such as:
- **Adjusted Rand Index (ARI):** Measures the alignment between clusters and classes.
- **Calinski-Harabasz Index (CH):** Evaluates the dispersion of clusters.

This approach provides a more complete and robust analysis of the quality of the generated clustering.

"""

# Calculate the Adjusted Rand Index (ARI)
ari_score = adjusted_rand_score(df['User Behavior Class'], df['Cluster'])

print(f"Adjusted Rand Index (ARI): {ari_score:.4f}")

"""### üî¢ Evaluation with Adjusted Rand Index (ARI)

The **Adjusted Rand Index (ARI)** was used to measure the correspondence between the clusters generated by the clustering model and the original user behavior classes.

üìä **Result:**  
The calculated ARI value was **1.00**, indicating that the generated clusters perfectly match the original classes.

üìã **Interpretation:**  
An ARI of **1.00** means that the clustering model exactly replicated the divisions of the original classes. This confirms that the patterns identified by the clustering model are completely aligned with the labels provided in the dataset.

‚öôÔ∏è **Conclusion:**  
While the Silhouette Score indicated moderate cluster cohesion and separation (0.60), the ARI confirms that the clusters generated by the model are consistent and directly correspond to the original classes. This result reinforces that the variables chosen for clustering effectively capture user behavior and that the model segmented the data accurately.

üí° **Note:**  
The Silhouette Score evaluates only the geometric separation between clusters, while the ARI measures the alignment between clusters and the original classes. Despite a moderate Silhouette Score, the ARI confirms that the clusters are perfectly aligned with the predefined classes.

---
# üñºÔ∏è Cluster Visualization with PCA
"""

os.makedirs('results', exist_ok=True)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans.labels_, cmap='viridis')
plt.title('Clusters de Usu√°rios')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.colorbar()
plt.savefig('results/cluster_visualization.png')
plt.show()

"""---
# üìâ Cluster Graph Analysis (PCA)

The scatter plot using PCA shows the identified clusters projected in two dimensions.  
The colors represent the different clusters, with the color bar indicating the cluster labels.  

## Observations:
1. **Clear separation:** The clusters are well-separated in the graph, indicating that the model successfully distinguished patterns in the data.  
2. **Variation among points:** There is considerable variation in the positions of the points, suggesting that the clusters represent distinct usage behaviors.  
3. **Effectiveness of PCA:** The visual separation between clusters confirms the effectiveness of dimensionality reduction through PCA, making it easier to interpret the results.  

"""

# Calculate the mean for only numerical columns within each cluster
cluster_stats = df.groupby('Cluster').agg({col: 'mean' for col in df.select_dtypes(include=np.number).columns})
print(type(cluster_stats)) # Changed from cluster_stats.type() to type(cluster_stats)
print(cluster_stats)

"""---
# üöÄ Analysis of Cluster Results

After clustering, the clusters were analyzed based on the average values of the variables in each group. The results show distinct differences in usage patterns among the clusters.

- **Cluster 0:** Users with **high average daily app usage** and screen time. They exhibit **above-average battery drain**, indicating possible intensive app usage or devices with higher energy consumption.

- **Cluster 1:** Users with **moderate app usage** and **negative screen time** (below the general average). Battery consumption and the number of installed apps are also reduced.

- **Cluster 2:** Displays average values close to neutrality, indicating a more **balanced profile**, with characteristics that do not stand out significantly.

- **Cluster 3:** Characterized by **low battery consumption, installed apps, and data usage**, likely indicating **moderate or limited device usage.**

- **Cluster 4:** Users with **high average daily app and data usage** but moderate battery consumption. They demonstrate a profile that balances intensive usage with energy efficiency.

This analysis helps identify behavioral patterns that can be useful for targeted campaigns, resource optimization, or personalized recommendations.

---
### üí° Alternative: Clustering Without Direct Influence of Original Classes

In this section, we performed a new clustering analysis to ensure that the clusters generated by the model are entirely independent of the original classes provided in the dataset. To achieve this, we removed the `User Behavior Class` column before conducting the clustering, avoiding any direct influence from this variable.

#### üöÄ Method
- **Column Removal:** The `User Behavior Class` column was excluded from the dataset prior to the clustering process.
- **Variables Used:** Numerical columns related to mobile usage behavior, such as app usage time and battery consumption, were selected.
- **Data Normalization:** The `StandardScaler` was applied to ensure all numerical variables were on the same scale.
- **Algorithm Used:** We used K-Means with 5 clusters, aligned with the expected number of groups.
"""

# Update the dataset by removing the 'User Behavior Class' column
X_new = df.drop(columns=['User Behavior Class'])

# Select only the relevant numerical columns for clustering
numerical_columns = ['App Usage Time (min/day)', 'Screen On Time (hours/day)',
                     'Battery Drain (mAh/day)', 'Number of Apps Installed', 'Data Usage (MB/day)']
X_new = X_new[numerical_columns]

# Normalize the data again

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_new)

# Re-run the clustering with K-Means

kmeans = KMeans(n_clusters=5, random_state=42)
kmeans.fit(X_scaled)

# Add the new labels to the dataset
df['New Cluster'] = kmeans.labels_

# Evaluate the clusters

silhouette_new = silhouette_score(X_scaled, kmeans.labels_)
print(f"New Silhouette Score: {silhouette_new:.2f}")


# Calculate the Adjusted Rand Index (ARI)
ari_score = adjusted_rand_score(df['User Behavior Class'], df['Cluster'])

print(f"Adjusted Rand Index (ARI): {ari_score:.4f}")

"""### üìä Results of the New Clustering Analysis

After performing clustering without the influence of the original `User Behavior Class` column, we obtained the following results:

- **Silhouette Score:** 0.60  
  The Silhouette Score remains the same, indicating moderate quality in cluster separation and cohesion. This result reinforces that the geometric structure of the data still shows some overlap among groups but identifies relevant patterns.

- **Adjusted Rand Index (ARI):** 1.0000  
  The perfect ARI indicates that even without the direct influence of the original class column, the clusters generated by the clustering model exactly replicated the previously existing segmentation.

#### üìà Conclusion
The analysis shows that the variables chosen for clustering faithfully represent user behavior. The perfect correspondence between clusters and classes suggests that the model was able to precisely identify behavioral patterns, even without prior label information.

This result validates the robustness of the selected variables and reinforces the applicability of the model in real-world contexts, such as identifying user groups based on unlabeled data.

## üìÇ Dataset Source

This project used the **"Mobile Device Usage and User Behavior Dataset"**, available on Kaggle.  

üîó **Dataset Link:** [Mobile Device Usage and User Behavior Dataset](https://www.kaggle.com/datasets/valakhorasani/mobile-device-usage-and-user-behavior-dataset)

üìú **Dataset Description**:  
The dataset provides detailed information on the behavior of mobile device users, including usage time, battery consumption, demographics, and more. It is an excellent resource for analyzing behavioral patterns and user segmentation.

üôå **Acknowledgment**:  
We thank the dataset creators for making this valuable resource available to the community.
"""

